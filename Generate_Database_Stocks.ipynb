{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create_Database_Stock.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-d3hR30sELo"
      },
      "source": [
        "# import libraries\r\n",
        "import math\r\n",
        "from datetime import date, timedelta\r\n",
        "import pandas_datareader as web\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sqlalchemy import create_engine\r\n",
        "\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, LSTM\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koigEESosGnR",
        "outputId": "58752295-21ca-4f1b-c7cc-8a3fe7483e09"
      },
      "source": [
        "# I will be considering dates of stock ranging from current date(today) to 600 days from current day for analysis\r\n",
        "today = date.today()\r\n",
        "prev_600 = (today - timedelta(600)).strftime(\"%Y-%m-%d\")\r\n",
        "print(prev_600, today)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-16 2021-03-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNB2W5GVsKNA"
      },
      "source": [
        "# Prediction for stock are based on the following steps:-\r\n",
        "# Creating the dataframe by using YAHOO as datasource, today and prev_600 dates\r\n",
        "# Split the dataframe into train and test dataset.\r\n",
        "# Defining the model. I have used LSTM for this task, which is a variation of Recurrent Neural Network.\r\n",
        "# Fit the model by using train dataset\r\n",
        "# Predict the stock prices based on test dataset\r\n",
        "# Finally store the Date, Actual Price and Prediction price in the database named after Stock\r\n",
        "\r\n",
        "def process_predict_generate_data(stock):\r\n",
        "  df = web.DataReader(stock+'.NS', data_source='yahoo', start=prev_600, end=today)\r\n",
        "  data = df.filter(['Close'])\r\n",
        "  dataset = data.values\r\n",
        "  training_data_len = math.ceil(len(dataset)*.8)\r\n",
        "\r\n",
        "  # Scaling the data\r\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\r\n",
        "  scaled_data = scaler.fit_transform(dataset)\r\n",
        "\r\n",
        "  # Creating training dataset\r\n",
        "  train_data = scaled_data[0:training_data_len, : ]\r\n",
        "  x_train = []\r\n",
        "  y_train = []\r\n",
        "  for i in range(60, len(train_data)):\r\n",
        "    x_train.append(train_data[i-60:i, 0])\r\n",
        "    y_train.append(train_data[i, 0])\r\n",
        "\r\n",
        "  x_train, y_train = np.array(x_train), np.array(y_train)\r\n",
        "  x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\r\n",
        "\r\n",
        "  # Building LSTM model\r\n",
        "  model = Sequential()\r\n",
        "  model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\r\n",
        "  model.add(LSTM(50,return_sequences=False))\r\n",
        "  model.add(Dense(25))\r\n",
        "  model.add(Dense(1))\r\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\r\n",
        "  model.fit(x_train, y_train, batch_size=1, epochs=1, verbose=1)\r\n",
        "\r\n",
        "  # Creating testing dataset\r\n",
        "  test_data = scaled_data[training_data_len - 60: , :]\r\n",
        "  x_test = []\r\n",
        "  y_test = dataset[training_data_len:, :]\r\n",
        "  for i in range(60, len(test_data)):\r\n",
        "    x_test.append(test_data[i-60:i, 0])\r\n",
        "  x_test = np.array(x_test)\r\n",
        "  x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1))\r\n",
        "\r\n",
        "  #Get the predictions\r\n",
        "  predictions = model.predict(x_test)\r\n",
        "  predictions = scaler.inverse_transform(predictions)\r\n",
        "\r\n",
        "  train = data[: training_data_len]\r\n",
        "  valid = data[training_data_len: ]\r\n",
        "  valid['Predictions'] = predictions\r\n",
        "  valid['Date'] = valid.index\r\n",
        "  database_filename = stock+'.db'\r\n",
        "  engine = create_engine('sqlite:///{}'.format(database_filename))\r\n",
        "\r\n",
        "  table_name = database_filename.split('.')[0]\r\n",
        "  valid.to_sql(table_name, engine, index=False, if_exists = 'replace')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBWrq4ynyRmr"
      },
      "source": [
        "# List of stock on which Predictions are done.\r\n",
        "# Note: These are stocks in NIFTY50\r\n",
        "stock_data = [\r\n",
        "  \"ADANIPORTS\",\"ASIANPAINT\",\"AXISBANK\",\"BAJAJ-AUTO\",\r\n",
        "  \"BAJFINANCE\",\"BAJAJFINSV\",\"BPCL\",\"BHARTIARTL\",\"BRITANNIA\",\r\n",
        "  \"CIPLA\",\"COALINDIA\",\"DIVISLAB\",\"DRREDDY\",\"EICHERMOT\",\r\n",
        "  \"GAIL\",\"GRASIM\",\"HCLTECH\",\"HDFCBANK\",\"HDFCLIFE\",\"HEROMOTOCO\",\r\n",
        "  \"HINDALCO\",\"HINDUNILVR\",\"HDFC\",\"ICICIBANK\",\"ITC\",\"IOC\",\"INDUSINDBK\",\r\n",
        "  \"INFY\",\"JSWSTEEL\",\"KOTAKBANK\",\"LT\",\"M&M\",\"MARUTI\",\"NTPC\",\"NESTLEIND\",\r\n",
        "  \"ONGC\",\"POWERGRID\",\"RELIANCE\",\"SBILIFE\",\"SHREECEM\",\"SBIN\",\"SUNPHARMA\",\"TCS\",\r\n",
        "  \"TATAMOTORS\",\"TATASTEEL\",\"TECHM\",\"TITAN\",\"UPL\",\"ULTRACEMCO\",\"WIPRO\"\r\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPhvEs_UweQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c9f381-619c-438d-f05a-f3d6fa108af4"
      },
      "source": [
        "# Iterate through stock_data and perform processing on each stock \r\n",
        "for stock in stock_data:\r\n",
        "  process_predict_generate_data(stock)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "265/265 [==============================] - 8s 22ms/step - loss: 0.0060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L4PKtZ7WX21i",
        "outputId": "b5e6ce29-e0d4-4cad-a9d6-66db7b869473"
      },
      "source": [
        "# Compress the list of database into zip filed named as 'data.zip' and finally download it\r\n",
        "!zip -r data.zip .\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "files.download(\"data.zip\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: .config/ (stored 0%)\n",
            "updating: .config/logs/ (stored 0%)\n",
            "updating: .config/logs/2021.03.01/ (stored 0%)\n",
            "updating: .config/logs/2021.03.01/14.34.56.151354.log (deflated 53%)\n",
            "updating: .config/logs/2021.03.01/14.35.29.900487.log (deflated 54%)\n",
            "updating: .config/logs/2021.03.01/14.35.09.556851.log (deflated 87%)\n",
            "updating: .config/logs/2021.03.01/14.34.37.071843.log (deflated 92%)\n",
            "updating: .config/logs/2021.03.01/14.35.14.752951.log (deflated 54%)\n",
            "updating: .config/logs/2021.03.01/14.35.29.380461.log (deflated 54%)\n",
            "updating: .config/.last_update_check.json (deflated 25%)\n",
            "updating: .config/config_sentinel (stored 0%)\n",
            "updating: .config/.last_survey_prompt.yaml (stored 0%)\n",
            "updating: .config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "updating: .config/active_config (stored 0%)\n",
            "updating: .config/gce (stored 0%)\n",
            "updating: .config/configurations/ (stored 0%)\n",
            "updating: .config/configurations/config_default (deflated 15%)\n",
            "updating: HINDALCO.db (deflated 82%)\n",
            "updating: KOTAKBANK.db (deflated 82%)\n",
            "updating: SHREECEM.db (deflated 82%)\n",
            "updating: POWERGRID.db (deflated 83%)\n",
            "updating: IOC.db (deflated 82%)\n",
            "updating: INFY.db (deflated 83%)\n",
            "updating: BAJAJ-AUTO.db (deflated 82%)\n",
            "updating: NTPC.db (deflated 83%)\n",
            "updating: TCS.db (deflated 82%)\n",
            "updating: JSWSTEEL.db (deflated 82%)\n",
            "updating: BRITANNIA.db (deflated 82%)\n",
            "updating: DRREDDY.db (deflated 82%)\n",
            "updating: BHARTIARTL.db (deflated 83%)\n",
            "updating: BAJFINANCE.db (deflated 82%)\n",
            "updating: RELIANCE.db (deflated 82%)\n",
            "updating: LT.db (deflated 82%)\n",
            "updating: ONGC.db (deflated 82%)\n",
            "updating: ULTRACEMCO.db (deflated 82%)\n",
            "updating: INDUSINDBK.db (deflated 82%)\n",
            "updating: M&M.db (deflated 82%)\n",
            "updating: NESTLEIND.db (deflated 82%)\n",
            "updating: BAJAJFINSV.db (deflated 82%)\n",
            "updating: SBIN.db (deflated 82%)\n",
            "updating: WIPRO.db (deflated 82%)\n",
            "updating: MARUTI.db (deflated 82%)\n",
            "updating: TATASTEEL.db (deflated 82%)\n",
            "updating: CIPLA.db (deflated 83%)\n",
            "updating: HDFC.db (deflated 82%)\n",
            "updating: GRASIM.db (deflated 82%)\n",
            "updating: SUNPHARMA.db (deflated 82%)\n",
            "updating: .ipynb_checkpoints/ (stored 0%)\n",
            "updating: DIVISLAB.db (deflated 82%)\n",
            "updating: COALINDIA.db (deflated 83%)\n",
            "updating: ADANIPORTS.db (deflated 82%)\n",
            "updating: BPCL.db (deflated 82%)\n",
            "updating: HEROMOTOCO.db (deflated 82%)\n",
            "updating: TITAN.db (deflated 82%)\n",
            "updating: TECHM.db (deflated 82%)\n",
            "updating: HDFCBANK.db (deflated 82%)\n",
            "updating: UPL.db (deflated 82%)\n",
            "updating: HDFCLIFE.db (deflated 83%)\n",
            "updating: GAIL.db (deflated 82%)\n",
            "updating: AXISBANK.db (deflated 82%)\n",
            "updating: ITC.db (deflated 82%)\n",
            "updating: ASIANPAINT.db (deflated 82%)\n",
            "updating: HCLTECH.db (deflated 82%)\n",
            "updating: HINDUNILVR.db (deflated 82%)\n",
            "updating: EICHERMOT.db (deflated 82%)\n",
            "updating: SBILIFE.db (deflated 83%)\n",
            "updating: ICICIBANK.db (deflated 82%)\n",
            "updating: TATAMOTORS.db (deflated 82%)\n",
            "updating: sample_data/ (stored 0%)\n",
            "updating: sample_data/anscombe.json (deflated 83%)\n",
            "updating: sample_data/README.md (deflated 42%)\n",
            "updating: sample_data/california_housing_test.csv (deflated 76%)\n",
            "updating: sample_data/mnist_train_small.csv (deflated 88%)\n",
            "updating: sample_data/mnist_test.csv (deflated 88%)\n",
            "updating: sample_data/california_housing_train.csv (deflated 79%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_11baffdc-327e-460f-91e0-b8345cb054a2\", \"data.zip\", 7152402)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}